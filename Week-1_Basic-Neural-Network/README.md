# Week 1 â€“ Basic Neural Network from Scratch

##Task Description

 The objective of this task was to implement a basic neural network from scratch without using any deep learning frameworks such as TensorFlow or PyTorch.

##What I Implemented
 1. Forward propagation
 2. Loss calculation
 3. Backpropagation
 4. Weight and bias updates
 5. Training loop with multiple epochs

##Technologies Used
 1. Python
 2. NumPy
 3. Matplotlib

##How to Run the Project
 1. Open the notebook `WeIntern_Task_1.ipynb` from the `code` folder.
 2. Run all cells sequentially.
 3. Observe the loss values printed for each epoch.
 4. View the loss vs epochs graph generated at the end.

##Output

The model shows a gradual decrease in loss over epochs, indicating that the neural network is learning properly.

##Learnings
 1. Understood how neural networks work internally.
 2. Learned how backpropagation updates weights.
 3. Gained clarity on loss minimization and training flow.
